x-base_service: &base_service
    ports:
      - "${WEBUI_PORT:-7860}:7860"
    volumes:
      - &v1 ./data:/data
      - &v2 output:/output
      - &v3 models:/stable-diffusion/models
      - &v4 ./data/config/comfy/custom_nodes:/stable-diffusion/custom_nodes
      - &v5 ./data/user:/stable-diffusion/user
      - &v6 ./data/web/scripts/defaultGraph.js:/stable-diffusion/web/scripts/defaultGraph.js
    stop_signal: SIGKILL
    restart: unless-stopped
    tty: true
    healthcheck:
      test: ["CMD", "curl", "-f", "-i", "http://localhost:7860/"]
      interval: 1m
      timeout: 20s
      retries: 3
      start_period: 1m
    logging:    
      # https://docs.docker.com/engine/admin/logging/splunk/#splunk-options
      driver: splunk
      options:
        splunk-token: 95b7f38d-83cc-425e-95a1-da7a2bd90a47
        splunk-verify-connection: "false"
        splunk-url: http://splunk.odt.net:8088/
        labels: ai-odt-net,comfyui
        tag: "[Container: {{.Name}}/{{.ID}}] [Image: {{.ImageName}}] [ENV=production]"
    deploy:
      resources:
        reservations:
          devices:
              - driver: nvidia
                device_ids: ['0']
                capabilities: [compute, utility]

name: webui-docker

services:
  download:
    build: ./services/download/
    profiles: ["download"]
    volumes:
      - *v1

  auto: &automatic
    <<: *base_service
    profiles: ["auto"]
    build: ./services/AUTOMATIC1111
    image: sd-auto:78
    environment:
      - CLI_ARGS=--allow-code --medvram --xformers --enable-insecure-extension-access --api

  auto-cpu:
    <<: *automatic
    profiles: ["auto-cpu"]
    deploy: {}
    environment:
      - CLI_ARGS=--no-half --precision full --allow-code --enable-insecure-extension-access --api

  comfy: &comfy
    <<: *base_service
    profiles: ["comfy"]
    build: ./services/comfy/
    image: sd-comfy:7
    environment:
      - CLI_ARGS=--highvram --multi-user
      #- CLI_ARGS=--enable-cors-header http://localhost:3000 --highvram --multi-user --disable-metadata


  comfy-cpu:
    <<: *comfy
    profiles: ["comfy-cpu"]
    deploy: {}
    environment:
      - CLI_ARGS=--cpu

volumes:
  output:
  models: